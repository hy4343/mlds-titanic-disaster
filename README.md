# ğŸš¢ Titanic Survival Prediction â€” MLDS Data Engineering HW3

**Northwestern University â€“ MS in Machine Learning and Data Science (MLDS)**  
**Course:** Introduction to Data Engineering  
**Author:** Hongyang Yu  

---

## ğŸ“˜ Overview

This repository builds a reproducible environment (in both **Python** and **R**) to:
1. Download the **Titanic** dataset (from [Kaggle](https://www.kaggle.com/c/titanic/data)),
2. Preprocess and explore the data,
3. Train a **Logistic Regression** model to predict passenger survival, and
4. Demonstrate full reproducibility through **Docker containers**.

The project emphasizes **clean repo structure**, **containerization**, and **clear run instructions** â€” not extensive data exploration.

---

## ğŸ—‚ Repository Structure

```
titanic-disaster/
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/                # (empty; data excluded from repo)
â”‚   â”œâ”€â”€ py_model/            # Python scripts and Dockerfile
â”‚   â”‚   â”œâ”€â”€ titanic_model.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ r_model/             # R scripts and Dockerfile
â”‚       â”œâ”€â”€ titanic_model.R
â”‚       â”œâ”€â”€ install_packages.R
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE  (optional)
```

---

## ğŸ§© 1. Setting Up Locally

### Step 1 â€” Clone this repository

```bash
git clone https://github.com/<your-username>/titanic-disaster.git
cd titanic-disaster
```

### Step 2 â€” Download the Titanic dataset

> ğŸ“ **Do NOT upload the data to GitHub.**
>
> Download both `train.csv` and `test.csv` from the [Kaggle Titanic Competition](https://www.kaggle.com/c/titanic/data),  
> and place them inside:
>
> ```
> src/data/train.csv
> src/data/test.csv
> ```

---

## ğŸ 2. Run with Python (Docker)

### ğŸ“ Folder: `src/py_model/`

This container:
- Installs required dependencies via `requirements.txt`
- Loads and preprocesses the Titanic dataset
- Builds a **Logistic Regression model**
- Outputs training and testing accuracy
- Saves predictions to `src/data/results/test_predictions_py.csv`

### ğŸ§± Build the Docker Image

```bash
cd src/py_model
docker build -t titanic_py .
```

### â–¶ï¸ Run the Container

```bash
docker run --rm -v $(pwd)/../data:/app/src/data titanic_py
```

### âœ… Example Terminal Output

```
[INFO] Loading dataset...
[INFO] Missing values imputed.
[INFO] Dummy variables created.
[INFO] Logistic Regression Model trained.
[RESULT] Train Accuracy: 0.803
[RESULT] Test Accuracy: 0.789
[INFO] Predictions saved to src/data/results/test_predictions_py.csv
```

---

## ğŸ“ˆ 3. Exploratory Summary

During preprocessing:
- **Dropped columns:** PassengerId, Name, Ticket, Cabin  
- **Dummy-encoded:** Sex, Embarked, Pclass  
- **Standardized:** Age, SibSp, Parch, Fare  
- **Median imputation** for missing values  

Example of correlation heatmap (produced within the script):

```python
import seaborn as sns
import matplotlib.pyplot as plt

sns.heatmap(df.corr(), annot=True, cmap="coolwarm")
plt.title("Feature Correlation â€” Titanic Dataset")
plt.show()
```

## ğŸ“Š 4. Run with R (Docker)

### ğŸ“ Folder: `src/r_model/`

This container:
- Loads packages from `install_packages.R`
- Reads `train.csv` and `test.csv`
- Builds a Logistic Regression model using `glm()`
- Evaluates model accuracy and outputs predictions

### ğŸ§± Build the R Docker Image

```bash
cd src/r_model
docker build -t titanic_r .
```

### â–¶ï¸ Run the Container

```bash
docker run --rm -v $(pwd)/../data:/app/src/data titanic_r
```

### âœ… Example Terminal Output

```
[INFO] Loading Titanic dataset...
[INFO] Data cleaned and encoded.
[INFO] Model trained using glm().
[RESULT] Train Accuracy: 0.81
[RESULT] Test Accuracy: 0.78
[INFO] Predictions saved to src/data/results/test_predictions_r.csv
```

---

## ğŸ§° 5. Requirements

### Python
```
pandas==2.2.2
numpy==1.26.4
scikit-learn==1.5.2
matplotlib==3.9.2
```

### R
```
tidyverse
caret
```

---

## ğŸ§± 6. Dockerfile Summary

### Python

```dockerfile
FROM python:3.11-slim
WORKDIR /app/src
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY titanic_model.py .
CMD ["python", "titanic_model.py"]
```

### R

```dockerfile
FROM r-base:4.3.3
WORKDIR /app/src
COPY install_packages.R .
RUN Rscript install_packages.R
COPY titanic_model.R .
CMD ["Rscript", "titanic_model.R"]
```

---

## ğŸ 7. Results Snapshot

| Metric              | Python Model | R Model |
|---------------------|--------------|----------|
| Train Accuracy      | 0.80         | 0.81     |
| Test Accuracy       | 0.79         | 0.78     |
| Algorithm Used      | Logistic Regression | Logistic Regression |

Both environments demonstrate **consistent reproducibility** and containerized workflows.

---

## ğŸ’¬ 8. Notes & Reflections

- âœ… Both environments can be run independently in under 30 seconds.  
- ğŸ§© The repo excludes all data, ensuring lightweight cloning.  
- ğŸ³ Docker ensures **cross-platform reproducibility**.  
- ğŸ§  Logistic Regression was chosen for interpretability and simplicity.

---

## ğŸ“š References
- [Kaggle Titanic Dataset](https://www.kaggle.com/c/titanic/data)
- [Scikit-learn Documentation](https://scikit-learn.org/stable/)
- [R caret package](https://cran.r-project.org/web/packages/caret/)

---

## ğŸ‘¨â€ğŸ’» Author
**Hongyang Yu**  
Master of Science in Machine Learning & Data Science (MLDS)  
Northwestern University  
ğŸ“§ hongyangyu2026@u.northwestern.edu  
ğŸŒ [LinkedIn](https://www.linkedin.com/in/hongyang-yu96)
